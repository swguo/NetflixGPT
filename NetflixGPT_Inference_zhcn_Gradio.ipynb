{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TnKYQrpDiwl3",
    "outputId": "ce6d24a5-960d-4cc3-ae88-9e5102259eab"
   },
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tp0frphhiMK4",
    "outputId": "aaf8d842-b84b-46a6-b15d-dae327db7be3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(21131, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=21131, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, GPT2LMHeadModel\n",
    "import gradio as gr\n",
    "import asyncio\n",
    "\n",
    "# 設定裝置為 GPU 或 CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 載入訓練好的模型和 tokenizer\n",
    "model_path = \"./NetflixGPT-chinese\"  # 修改為你訓練模型的儲存路徑\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rDUw0ltFifcq"
   },
   "outputs": [],
   "source": [
    "# Define the description generation function with mode selection\n",
    "def generate_description(title, mode=\"greedy\", max_length=512, temperature=0.7, top_k=50, top_p=0.3):\n",
    "    # Prepare input text\n",
    "    input_text = f\"標題: {title} 描述:\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate text based on the selected mode\n",
    "    with torch.no_grad():\n",
    "        if mode == \"beam\":\n",
    "            output = model.generate(\n",
    "                input_ids,\n",
    "                max_length=max_length,\n",
    "                temperature=temperature,  # Control randomness\n",
    "                top_k=top_k,              # Limit to top-k words                \n",
    "                do_sample=True,           # 啟用隨機抽樣\n",
    "                top_p=top_p,\n",
    "                no_repeat_ngram_size=2,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        else:  # Default to greedy decoding\n",
    "            output = model.generate(\n",
    "                input_ids,\n",
    "                max_length=max_length,\n",
    "                no_repeat_ngram_size=2,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                early_stopping=True\n",
    "            )\n",
    "\n",
    "    # Decode the generated description\n",
    "    generated_text = tokenizer.decode(output[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
    "    return generated_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "id": "Ydx7YzEDiuHI",
    "outputId": "ccb5be4d-a4db-42e9-fe78-eee15146f7c9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\swguo\\anaconda3\\lib\\site-packages\\gradio\\utils.py:1002: UserWarning: Expected 5 arguments for function <function display_text at 0x000001FB8271AF70>, received 2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\swguo\\anaconda3\\lib\\site-packages\\gradio\\utils.py:1006: UserWarning: Expected at least 5 arguments for function <function display_text at 0x000001FB8271AF70>, received 2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7872\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\swguo\\anaconda3\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:638: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define async function for progressive display\n",
    "async def display_text(title, mode, temperature, top_k, top_p):\n",
    "    description = generate_description(title, mode=mode, temperature=temperature, top_k=top_k, top_p=top_p)\n",
    "    displayed_text = \"\"\n",
    "    for char in description:\n",
    "        displayed_text += char\n",
    "        await asyncio.sleep(0.05)  # Adjust speed of character display\n",
    "        yield displayed_text\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=display_text,\n",
    "    inputs=[\n",
    "        gr.Dropdown(choices=[\"精神病特工\", \"追星女孩\", \"非法女人\"], label=\"Select a Title\"),\n",
    "        gr.Radio(choices=[\"greedy\", \"beam\"], value=\"greedy\", label=\"Generation Mode\")\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Generated Description\"),\n",
    "    title=\"Netflix Title Description Generator\",\n",
    "    description=\"Select a Netflix title and generation mode (greedy or beam search with temperature, top-k, and top-p) to view the model's generated description.\"\n",
    ")\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=display_text,\n",
    "    inputs=[\n",
    "        gr.Dropdown(choices=[\"精神病特工\", \"追星女孩\", \"非法女人\"], label=\"Select a Title\"),\n",
    "        gr.Radio(choices=[\"greedy\", \"beam\"], value=\"greedy\", label=\"Generation Mode\"),\n",
    "        gr.Slider(minimum=0.1, maximum=1.0, value=0.7, label=\"Temperature\"),\n",
    "        gr.Slider(minimum=1, maximum=100, step=1, value=50, label=\"Top-K\"),\n",
    "        gr.Slider(minimum=0.1, maximum=1.0, step=0.1, value=0.3, label=\"Top-P\"),\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Generated Description\"),\n",
    "    title=\"Netflix Title Description Generator\",\n",
    "    description=\"Select a Netflix title and customize generation parameters to view the model's generated description.\"\n",
    ")\n",
    "\n",
    "\n",
    "# Launch Gradio interface\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
