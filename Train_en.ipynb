{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8dd1faa-73d5-4e70-8c48-fa240f035fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55be448a-0ebf-44d0-a38d-9d2ab7531636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50260, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 設定使用單個 GPU\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# 初始化 tokenizer 並添加特殊標記\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', \n",
    "                                          bos_token='<|startoftext|>',\n",
    "                                          eos_token='<|endoftext|>',\n",
    "                                          pad_token='<|pad|>')\n",
    "tokenizer.add_special_tokens({\"sep_token\": \"<|sep|>\"})\n",
    "\n",
    "# 加載 GPT-2 模型並調整詞彙表大小\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31eb4e04-2561-4008-a394-7f583febc2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取 netflix_titles.csv 並選取 title 和 description 欄位\n",
    "data = pd.read_csv('data/netflix_en.csv')\n",
    "data = data[['title', 'description']]\n",
    "\n",
    "# 將 pandas DataFrame 轉換為 Hugging Face 的 Dataset 並劃分訓練和測試集\n",
    "dataset = Dataset.from_pandas(data)\n",
    "train_test_split = dataset.train_test_split(test_size=0.2)\n",
    "datasets = DatasetDict({\n",
    "    'train': train_test_split['train'],\n",
    "    'test': train_test_split['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d346881-3d11-49f7-b83a-686826874adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 train 和 test 資料分別轉換為 pandas DataFrame\n",
    "train_df = train_test_split['train'].to_pandas()\n",
    "test_df = train_test_split['test'].to_pandas()\n",
    "\n",
    "# 將 DataFrame 保存為 CSV 文件\n",
    "train_df.to_csv('data/netflix_train.csv', index=False)\n",
    "test_df.to_csv('data/netflix_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d229aec-9781-4faa-b10b-349d6faa5041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 tokenization 函數，處理 input_ids 和 labels\n",
    "def tokenize_function(example):\n",
    "    text = f\"<|startoftext|>Title: {example['title']}<|sep|>Description: {example['description']}<|endoftext|>\"\n",
    "    tokens = tokenizer(\n",
    "        text,\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    input_ids = tokens['input_ids']\n",
    "    \n",
    "    # 確定 <|sep|> 的索引，並設置 labels\n",
    "    sep_token_id = tokenizer.convert_tokens_to_ids(\"<|sep|>\")\n",
    "    if sep_token_id in input_ids:\n",
    "        sep_index = input_ids.index(sep_token_id)\n",
    "    else:\n",
    "        sep_index = -1\n",
    "\n",
    "    # 將 labels 複製自 input_ids，並忽略標題部分和填充部分的損失計算\n",
    "    labels = input_ids.copy()\n",
    "    if sep_index != -1:\n",
    "        for i in range(sep_index + 1):\n",
    "            labels[i] = -100\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "    labels = [label if label != pad_token_id else -100 for label in labels]\n",
    "    tokens['labels'] = labels\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "159b0ea3-4d26-4a07-9859-895a160e2f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ff4687077044fa853522e5c8ab437f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7045 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aeffe3871bf4ceba4e3939fc13185f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1762 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 應用 tokenization 函數\n",
    "tokenized_datasets = datasets.map(tokenize_function, remove_columns=[\"title\", \"description\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19d929bf-36c2-40d0-b809-ce3092a87ee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 1\n",
      "})\n",
      "inputs:\n",
      "<|startoftext|>Title: The Debt Collector<|sep|>Description: A broke martial arts instructor takes a side gig with a mobster, who pairs him with a veteran thug for a weekend of fisticuffs-fueled debt collection.<|endoftext|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|>\n",
      "labels:\n",
      "[-100, -100, -100, -100, -100, -100, -100, 11828, 25, 317, 6265, 15618, 10848, 21187, 2753, 257, 1735, 12526, 351, 257, 7251, 1706, 11, 508, 14729, 683, 351, 257, 9298, 47641, 329, 257, 5041, 286, 277, 2569, 18058, 12, 25802, 276, 5057, 4947, 13, 50256, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "Description: A broke martial arts instructor takes a side gig with a mobster, who pairs him with a veteran thug for a weekend of fisticuffs-fueled debt collection.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# 或者查看隨機一筆資料\n",
    "random_example = tokenized_datasets['train'].shuffle(seed=42).select([0])\n",
    "print(random_example)\n",
    "generated_text = tokenizer.decode(random_example['input_ids'][0], skip_special_tokens=False)\n",
    "print('inputs:')\n",
    "print(generated_text)\n",
    "print('labels:')\n",
    "print(random_example['labels'][0])\n",
    "generated_text = tokenizer.decode([token for token in random_example['labels'][0] if token != -100], skip_special_tokens=False)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bb8d037-a5fa-412c-8d1d-b7f7dec4385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定訓練參數\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./NetflixGPT-english\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    eval_steps=200,\n",
    "    save_steps=200,\n",
    "    save_total_limit=1,\n",
    "    logging_steps=200,\n",
    "    report_to=\"none\"  # Disable wandb or other integrations\n",
    ")\n",
    "\n",
    "# 初始化 Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d98d5e5-f0ff-4855-9b8b-da9f42a3c5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4420' max='4420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4420/4420 22:09, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.723500</td>\n",
       "      <td>3.223100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.282400</td>\n",
       "      <td>3.175246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.186100</td>\n",
       "      <td>3.157892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.116500</td>\n",
       "      <td>3.148762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.051000</td>\n",
       "      <td>3.142247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.999100</td>\n",
       "      <td>3.141649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.953400</td>\n",
       "      <td>3.138440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.914200</td>\n",
       "      <td>3.142920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.866600</td>\n",
       "      <td>3.152623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.837500</td>\n",
       "      <td>3.149310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.801200</td>\n",
       "      <td>3.151133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.767700</td>\n",
       "      <td>3.155369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.743000</td>\n",
       "      <td>3.160819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.721300</td>\n",
       "      <td>3.170052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.696600</td>\n",
       "      <td>3.171588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>2.671100</td>\n",
       "      <td>3.180317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>2.664500</td>\n",
       "      <td>3.183125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>2.643900</td>\n",
       "      <td>3.185575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>2.628300</td>\n",
       "      <td>3.188913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.626700</td>\n",
       "      <td>3.190670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>2.614500</td>\n",
       "      <td>3.192782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>2.612300</td>\n",
       "      <td>3.193858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Checkpoint destination directory ./gpt2-netflix/checkpoint-600 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/user_data/envs/LLMs/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4420, training_loss=2.9585331040809595, metrics={'train_runtime': 1330.137, 'train_samples_per_second': 105.929, 'train_steps_per_second': 3.323, 'total_flos': 9204011827200000.0, 'train_loss': 2.9585331040809595, 'epoch': 20.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 開始訓練\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a17b9607-293f-4947-9e9c-076aae54a8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./gpt2-netflix/tokenizer_config.json',\n",
       " './gpt2-netflix/special_tokens_map.json',\n",
       " './gpt2-netflix/vocab.json',\n",
       " './gpt2-netflix/merges.txt',\n",
       " './gpt2-netflix/added_tokens.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 假設模型和 tokenizer 的保存目錄為 \"./NetflixGPT-english\"\n",
    "tokenizer.save_pretrained(\"./NetflixGPT-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93978a11-9735-4f06-b7ab-e277401bc687",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8077582-8bd7-4225-b501-fd9327f4ff8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Stranger Things\n",
      "Generated Description: Title: Stranger Things Description: When a young woman is abducted by a group of strangers, the only way to save her is to be with them.\n",
      "--------------------------------------------------\n",
      "Title: Breaking Bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/envs/LLMs/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:453: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Description: Title: Breaking Bad Description: A group of friends is caught between two rivalries when a mysterious figure threatens to destroy their friendship.\n",
      "--------------------------------------------------\n",
      "Title: The Crown\n",
      "Generated Description: Title: The Crown Description: A young man's life is turned upside down when he's forced to marry a woman he loves, who's been cheating on him for years.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 定義 inference 測試函數\n",
    "def generate_description(title):\n",
    "    input_text = f\"<|startoftext|>Title: {title} <|sep|>Description:\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # 使用模型進行生成\n",
    "    output = model.generate(input_ids, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2, \n",
    "                            pad_token_id=tokenizer.eos_token_id, early_stopping=True)\n",
    "    \n",
    "    # 解碼生成的描述\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text.replace(input_text, \"\").strip()\n",
    "\n",
    "# 測試生成效果\n",
    "test_titles = [\"Stranger Things\", \"Breaking Bad\", \"The Crown\"]\n",
    "for title in test_titles:\n",
    "    print(f\"Title: {title}\")\n",
    "    print(\"Generated Description:\", generate_description(title))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c2377-3eef-4d53-a8b7-0be29a8f72af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d332477-c2b9-4e49-a2cc-c314b50fa020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0932243-354c-42db-933b-76ce6405b6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
