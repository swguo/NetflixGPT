{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "626f8c7b-01be-4f25-a5a7-8c676ee998c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec9adf63-47f5-4ace-9290-6ee76ef7c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定裝置為 GPU 或 CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "914492ab-41a0-4f67-980f-3fdae7eb3036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(21131, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=21131, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 載入訓練好的模型和 tokenizer\n",
    "model_path = \"./NetflixGPT-chinese\"  # 修改為你訓練模型的儲存路徑\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ba34a4-a0b6-42f2-adcc-b7e4827a4909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 inference 測試函數\n",
    "def generate_description(title):\n",
    "    input_text = f\"標題: {title} 描述:\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # 使用模型進行生成\n",
    "    output = model.generate(input_ids, max_length=512, num_return_sequences=1, no_repeat_ngram_size=2, \n",
    "                            pad_token_id=tokenizer.eos_token_id, early_stopping=True)\n",
    "    \n",
    "    # 解碼生成的描述\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    generated_text = ''.join(generated_text.split(' '))\n",
    "    new_input_text = ''.join(input_text.split(' '))\n",
    "    return generated_text.replace(new_input_text, \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "297dd306-51ff-429d-a34d-05d83855f784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: 精神病特工\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\swguo\\anaconda3\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:638: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Description: 特·格里爾斯和他的朋友們在一個小鎮上度過了一年的假期，他們的生活在他最好的時刻裡面臨著一些令人毛骨悚然的事情。\n",
      "--------------------------------------------------\n",
      "Title: 追星女孩\n",
      "Generated Description: 在一個小鎮上，一位年輕的女子在她的家鄉度過了一年的假期，她在那裡遇到了兩個女人，他們都在尋找自己的方法，並在這個時候遇見了他。\n",
      "--------------------------------------------------\n",
      "Title: 非法女人\n",
      "Generated Description: 在一個被一位女性拒絕的城市裡，一名女子在她的家裡被她所愛的女孩綁架，她在那裡遇到了一隻神秘的貓，並在這個女兒的生活被打破。\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 測試生成效果\n",
    "test_titles = [\"精神病特工\", \"追星女孩\", \"非法女人\"]\n",
    "for title in test_titles:\n",
    "    print(f\"Title: {title}\")\n",
    "    print(\"Generated Description:\", generate_description(title))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4cc81ef-ad75-4b55-a197-91d2f3b3d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義生成描述的函數（使用 top_k 和 temperature）\n",
    "def generate_description(title, max_length=512, top_k=50, temperature=0.7):\n",
    "    # 構建輸入文本，不添加特殊標記\n",
    "    input_text = f\"標題: {title} 描述:\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # 使用模型進行生成，設置 top_k 和 temperature\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length + len(input_ids[0]),  # 增加總長度限制\n",
    "            do_sample=True,                            # 啟用隨機抽樣\n",
    "            top_k=top_k,                               # 設置 top_k\n",
    "            temperature=temperature,                   # 設置 temperature\n",
    "            no_repeat_ngram_size=2,                    # 防止重複 n-grams\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "    \n",
    "    # 只提取生成的描述部分\n",
    "    generated_text = tokenizer.decode(output[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
    "    generated_text = ''.join(generated_text.split(' '))\n",
    "    new_input_text = ''.join(input_text.split(' '))\n",
    "    return generated_text.replace(new_input_text, \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00182a72-7a0d-48f3-8d33-fa63ae4593f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: 精神病特工\n",
      "Generated Description: 一位精明的醫生和一些有抱負的前疾病的單身同事，他們在與一個被診斷出異常後患有精子狀態的人合作，並建立了聯繫。\n",
      "--------------------------------------------------\n",
      "Title: 追星女孩\n",
      "Generated Description: hercleman和她的朋友們在一個受到她媽媽的阻礙的星球上穿梭，共同尋找失蹤的女兒。\n",
      "--------------------------------------------------\n",
      "Title: 非法女人\n",
      "Generated Description: 在她的婚姻關係中陷入僵局，一名法律系學生在一場意外中失蹤後，開始了一段新的關於生活，她和一位英俊的女性之間的愛情也開花了。\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 測試生成效果\n",
    "test_titles = [\"精神病特工\", \"追星女孩\", \"非法女人\"]\n",
    "for title in test_titles:\n",
    "    print(f\"Title: {title}\")\n",
    "    print(\"Generated Description:\", generate_description(title))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72fac62-7832-4613-94e1-28b5ae151aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11368b8e-7854-4e16-ac8d-a6476f288a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
